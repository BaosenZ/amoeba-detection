{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/BaosenZ/amoeba-detection/blob/master/level2_objectDetectionWithMaskRCNN/Solution_AmoebaDetection.ipynb","timestamp":1653659454025}],"collapsed_sections":["cgSmFfk0--o0"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","source":["# Solution: Amoeba Detection"],"metadata":{"id":"dWfF5ROjdKuG"}},{"cell_type":"markdown","source":["This is the solution for the assignment of amoeba detection. "],"metadata":{"id":"vro9ERPIj-kO"}},{"cell_type":"markdown","source":["We will introduce chemistry students to object detection with machine learning. We train our custom model with the images collected by ourselves in chemistry or biology lab. \n","\n"],"metadata":{"id":"2KernsIUdRyx"}},{"cell_type":"markdown","source":["## Table of content\n","\n","\n","* Set up environment\n","* Load images dataset\n","* Data preparation and configurations\n","* Train custom amoeba model\n","* Evaluate amoeba model\n","* Inference"],"metadata":{"id":"7M77-yL-dmr2"}},{"cell_type":"markdown","metadata":{"id":"Uv718omLXu64"},"source":["# Set up environment"]},{"cell_type":"markdown","source":["We will install Mask R-CNN repo from Github (https://github.com/matterport/Mask_RCNN) and necessary packages. We need to make sure the packages we are using is the correct version."],"metadata":{"id":"-xF51fTo80NT"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DP0XHZ_2ND6y","outputId":"041395ff-2a1e-45a2-804a-15d864e45e81","executionInfo":{"status":"ok","timestamp":1655762845568,"user_tz":240,"elapsed":77746,"user":{"displayName":"Baosen Zhang","userId":"17675451703526793530"}}},"source":["!pip install tensorflow==1.15.0\n","!pip install keras==2.1.6\n","!pip install h5py==2.10.0\n","!pip install scikit-image==0.16.2"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow==1.15.0\n","  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n","\u001b[K     |████████████████████████████████| 412.3 MB 25 kB/s \n","\u001b[?25hCollecting tensorflow-estimator==1.15.1\n","  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n","\u001b[K     |████████████████████████████████| 503 kB 68.4 MB/s \n","\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.14.1)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.21.6)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.17.3)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 54.7 MB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.46.3)\n","Collecting gast==0.2.2\n","  Downloading gast-0.2.2.tar.gz (10 kB)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.37.1)\n","Collecting keras-applications>=1.0.8\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 9.1 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (3.1.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (57.4.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.7)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.11.4)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.8.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.0) (1.5.2)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=c046cb6a7236a00cf23efed49d1c01345b7fb437c67d2d27518c298eee5d1262\n","  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n","Successfully built gast\n","Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.8.0\n","    Uninstalling tensorflow-estimator-2.8.0:\n","      Successfully uninstalled tensorflow-estimator-2.8.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.8.0\n","    Uninstalling tensorboard-2.8.0:\n","      Successfully uninstalled tensorboard-2.8.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.5.3\n","    Uninstalling gast-0.5.3:\n","      Successfully uninstalled gast-0.5.3\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.8.2+zzzcolab20220527125636\n","    Uninstalling tensorflow-2.8.2+zzzcolab20220527125636:\n","      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220527125636\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n","kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n","Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras==2.1.6\n","  Downloading Keras-2.1.6-py2.py3-none-any.whl (339 kB)\n","\u001b[K     |████████████████████████████████| 339 kB 27.2 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (1.15.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (1.21.6)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (3.1.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (1.4.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (3.13)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.1.6) (1.5.2)\n","Installing collected packages: keras\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.8.0\n","    Uninstalling keras-2.8.0:\n","      Successfully uninstalled keras-2.8.0\n","Successfully installed keras-2.1.6\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting h5py==2.10.0\n","  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 20.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.21.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n","Installing collected packages: h5py\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","Successfully installed h5py-2.10.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting scikit-image==0.16.2\n","  Downloading scikit_image-0.16.2-cp37-cp37m-manylinux1_x86_64.whl (26.5 MB)\n","\u001b[K     |████████████████████████████████| 26.5 MB 1.3 MB/s \n","\u001b[?25hRequirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (7.1.2)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (2.6.3)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (1.3.0)\n","Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (1.4.1)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (3.2.2)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (2.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio>=2.3.0->scikit-image==0.16.2) (1.21.6)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (1.4.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (1.15.0)\n","Installing collected packages: scikit-image\n","  Attempting uninstall: scikit-image\n","    Found existing installation: scikit-image 0.18.3\n","    Uninstalling scikit-image-0.18.3:\n","      Successfully uninstalled scikit-image-0.18.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed scikit-image-0.16.2\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hmEs1lZiN5hz","outputId":"46a944f0-546b-4d2d-b749-dd7d997db970","executionInfo":{"status":"ok","timestamp":1655762855727,"user_tz":240,"elapsed":10167,"user":{"displayName":"Baosen Zhang","userId":"17675451703526793530"}}},"source":["%%shell\n","# clone Mask_RCNN repo and install packages\n","git clone https://github.com/matterport/Mask_RCNN\n","cd Mask_RCNN\n","python setup.py install"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Mask_RCNN'...\n","remote: Enumerating objects: 956, done.\u001b[K\n","remote: Total 956 (delta 0), reused 0 (delta 0), pack-reused 956\u001b[K\n","Receiving objects: 100% (956/956), 125.23 MiB | 29.26 MiB/s, done.\n","Resolving deltas: 100% (565/565), done.\n","WARNING:root:Fail load requirements file, so using default ones.\n","/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:700: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n","  % (opt, underscore_opt))\n","/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:700: UserWarning: Usage of dash-separated 'license-file' will not be supported in future versions. Please use the underscore name 'license_file' instead\n","  % (opt, underscore_opt))\n","/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:700: UserWarning: Usage of dash-separated 'requirements-file' will not be supported in future versions. Please use the underscore name 'requirements_file' instead\n","  % (opt, underscore_opt))\n","running install\n","running bdist_egg\n","running egg_info\n","creating mask_rcnn.egg-info\n","writing mask_rcnn.egg-info/PKG-INFO\n","writing dependency_links to mask_rcnn.egg-info/dependency_links.txt\n","writing top-level names to mask_rcnn.egg-info/top_level.txt\n","writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n","reading manifest template 'MANIFEST.in'\n","adding license file 'LICENSE'\n","writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_py\n","creating build\n","creating build/lib\n","creating build/lib/mrcnn\n","copying mrcnn/utils.py -> build/lib/mrcnn\n","copying mrcnn/visualize.py -> build/lib/mrcnn\n","copying mrcnn/parallel_model.py -> build/lib/mrcnn\n","copying mrcnn/__init__.py -> build/lib/mrcnn\n","copying mrcnn/model.py -> build/lib/mrcnn\n","copying mrcnn/config.py -> build/lib/mrcnn\n","creating build/bdist.linux-x86_64\n","creating build/bdist.linux-x86_64/egg\n","creating build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/utils.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/visualize.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/parallel_model.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/__init__.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/model.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/config.py -> build/bdist.linux-x86_64/egg/mrcnn\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/utils.py to utils.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/visualize.py to visualize.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/parallel_model.py to parallel_model.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/model.py to model.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/config.py to config.cpython-37.pyc\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","copying mask_rcnn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying mask_rcnn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying mask_rcnn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying mask_rcnn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","zip_safe flag not set; analyzing archive contents...\n","creating dist\n","creating 'dist/mask_rcnn-2.1-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing mask_rcnn-2.1-py3.7.egg\n","Copying mask_rcnn-2.1-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n","Adding mask-rcnn 2.1 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.7/dist-packages/mask_rcnn-2.1-py3.7.egg\n","Processing dependencies for mask-rcnn==2.1\n","Finished processing dependencies for mask-rcnn==2.1\n"]},{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zqIPGkJEVsiw","outputId":"73ce6a32-3e38-4c46-ef2e-4f69c8a4e885","executionInfo":{"status":"ok","timestamp":1655762862616,"user_tz":240,"elapsed":6913,"user":{"displayName":"Baosen Zhang","userId":"17675451703526793530"}}},"source":["import os\n","import sys\n","import random\n","import math\n","import numpy as np\n","import skimage.io\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","# Root directory of the project\n","ROOT_DIR = os.path.abspath(\"./Mask_RCNN/\")\n","\n","# Import Mask RCNN\n","sys.path.append(ROOT_DIR)  # To find local version of the library\n","from mrcnn import utils\n","import mrcnn.model as modellib\n","from mrcnn import visualize\n","\n","# Import COCO config\n","sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # find local version\n","import coco\n","\n","%matplotlib inline \n","\n","# Directory to save logs and trained model\n","MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n","\n","# Local path to trained weights file\n","COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n","# Download COCO trained weights from Releases if needed\n","if not os.path.exists(COCO_MODEL_PATH):\n","    utils.download_trained_weights(COCO_MODEL_PATH)\n","\n","# Directory of images to run detection on\n","IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using TensorFlow backend.\n"]},{"output_type":"stream","name":"stdout","text":["Downloading pretrained model to /content/Mask_RCNN/mask_rcnn_coco.h5 ...\n","... done downloading pretrained model!\n"]}]},{"cell_type":"markdown","source":["# Load images dataset"],"metadata":{"id":"zO0KufAsfFD1"}},{"cell_type":"markdown","source":["We will clone the project from our github (https://github.com/BaosenZ/amoeba-detection.git). The dataset is included inside the github project."],"metadata":{"id":"LAUQRMDVG6sL"}},{"cell_type":"code","source":["# download dataset from github\n","\n","%%shell\n","git clone https://github.com/BaosenZ/amoeba-detection.git\n"],"metadata":{"id":"TyxOr0u5u5Ci","colab":{"base_uri":"https://localhost:8080/"},"outputId":"490adfad-e26c-4c47-c722-e70a4fb7edd8","executionInfo":{"status":"ok","timestamp":1655762878562,"user_tz":240,"elapsed":15971,"user":{"displayName":"Baosen Zhang","userId":"17675451703526793530"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'amoeba-detection'...\n","remote: Enumerating objects: 2453, done.\u001b[K\n","remote: Counting objects: 100% (378/378), done.\u001b[K\n","remote: Compressing objects: 100% (201/201), done.\u001b[K\n","remote: Total 2453 (delta 178), reused 376 (delta 177), pack-reused 2075\u001b[K\n","Receiving objects: 100% (2453/2453), 354.59 MiB | 33.44 MiB/s, done.\n","Resolving deltas: 100% (503/503), done.\n","Checking out files: 100% (3425/3425), done.\n"]},{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["# copy the dataset from github folder to 'content' \n","!cp -r '/content/amoeba-detection/dataset-section2/amoebaDataset/trainingDataset' '/content'\n","!cp -r '/content/amoeba-detection/dataset-section2/amoebaDataset/testDataset' '/content'"],"metadata":{"id":"B4JXR9TSu8ln"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z7H8c5VhVZwi"},"source":["# upload zip of the dataset from local\n","\n","# from google.colab import files\n","# uploaded = files.upload()\n","# for fn in uploaded.keys():\n","#     print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))\n","\n","# !unzip trainingDataset.zip\n","# !unzip testDataset.zip"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data preparation and configurations"],"metadata":{"id":"9zUpZ6MxdlON"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fCbodMuKJLeF","outputId":"b5ad5920-cf40-4549-fe1f-d47eb0382429","executionInfo":{"status":"ok","timestamp":1655762878918,"user_tz":240,"elapsed":8,"user":{"displayName":"Baosen Zhang","userId":"17675451703526793530"}}},"source":["from os import listdir\n","from xml.etree import ElementTree\n","from numpy import zeros\n","from numpy import asarray\n","from mrcnn.utils import Dataset\n","from mrcnn.config import Config\n","from mrcnn.model import MaskRCNN\n","\n","class AmoebaDataset(Dataset):\n","\tdef load_dataset(self, dataset_dir, is_train=True):\n","\t\t# Add classes\n","\t\tself.add_class(\"dataset\", 1, \"amoeba\")\n","\t\timages_dir = dataset_dir + '/images/'\n","\t\tannotations_dir = dataset_dir + '/annots/'\n","\t\tfor filename in listdir(images_dir):\n","\t\t\timage_id = filename[:-4]\n","\t\t\t# based on images number, split the training and validation data\n","\t\t\tif is_train and int(image_id) >= 170:\n","\t\t\t\tcontinue\n","\t\t\tif not is_train and int(image_id) < 170:\n","\t\t\t\tcontinue\n","\t\t\timg_path = images_dir + filename\n","\t\t\tann_path = annotations_dir + image_id + '.xml'\n","\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n","\n","\t# extract bounding boxes from an annotation file\n","\tdef extract_boxes(self, filename):\n","\t\ttree = ElementTree.parse(filename)\n","\t\troot = tree.getroot()\n","\t\tboxes = list()\n","\t\tfor box in root.findall('.//bndbox'):\n","\t\t\txmin = int(box.find('xmin').text)\n","\t\t\tymin = int(box.find('ymin').text)\n","\t\t\txmax = int(box.find('xmax').text)\n","\t\t\tymax = int(box.find('ymax').text)\n","\t\t\tcoors = [xmin, ymin, xmax, ymax]\n","\t\t\tboxes.append(coors)\n","\t\twidth = int(root.find('.//size/width').text)\n","\t\theight = int(root.find('.//size/height').text)\n","\t\treturn boxes, width, height\n","\n","\t# load the masks for an image\n","\tdef load_mask(self, image_id):\n","\t\tinfo = self.image_info[image_id]\n","\t\tpath = info['annotation']\n","\t\tboxes, w, h = self.extract_boxes(path)\n","\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n","\t\tclass_ids = list()\n","\t\tfor i in range(len(boxes)):\n","\t\t\tbox = boxes[i]\n","\t\t\trow_s, row_e = box[1], box[3]\n","\t\t\tcol_s, col_e = box[0], box[2]\n","\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n","\t\t\tclass_ids.append(self.class_names.index('amoeba'))\n","\t\treturn masks, asarray(class_ids, dtype='int32')\n","\n","\tdef image_reference(self, image_id):\n","\t\tinfo = self.image_info[image_id]\n","\t\treturn info['path']\n","\n","\n","# prepare train set\n","train_set = AmoebaDataset()\n","train_set.load_dataset('trainingDataset', is_train=True)\n","train_set.prepare()\n","print('Train: %d' % len(train_set.image_ids))\n","# prepare val set\n","val_set = AmoebaDataset()\n","val_set.load_dataset('trainingDataset', is_train=False)\n","val_set.prepare()\n","print('Val: %d' % len(val_set.image_ids))\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train: 169\n","Val: 27\n"]}]},{"cell_type":"markdown","source":["Config files allow you to separate the code from the parameters of the machine learning pipeline to help produce repeatable outcomes."],"metadata":{"id":"sQlnZkBEHLvQ"}},{"cell_type":"code","source":["# prepare config\n","class AmoebaConfig(Config):\n","\t# Give the configuration a recognizable name\n","\tNAME = \"amoeba_cfg\"\n","\t# Number of classes (including background)\n","\tNUM_CLASSES = 1 + 1 # background + 1 amoeba\n","\t# Use a small epoch since the data is simple\n","\tSTEPS_PER_EPOCH = 131\n","\tDETECTION_NMS_THRESHOLD = 0.5\n","\n","config = AmoebaConfig()\n","config.display()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ffweN5KiHBpS","executionInfo":{"status":"ok","timestamp":1655762879068,"user_tz":240,"elapsed":154,"user":{"displayName":"Baosen Zhang","userId":"17675451703526793530"}},"outputId":"576c8474-9353-48ce-bbe6-6c89c2f56f0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Configurations:\n","BACKBONE                       resnet101\n","BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n","BATCH_SIZE                     2\n","BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n","COMPUTE_BACKBONE_SHAPE         None\n","DETECTION_MAX_INSTANCES        100\n","DETECTION_MIN_CONFIDENCE       0.7\n","DETECTION_NMS_THRESHOLD        0.5\n","FPN_CLASSIF_FC_LAYERS_SIZE     1024\n","GPU_COUNT                      1\n","GRADIENT_CLIP_NORM             5.0\n","IMAGES_PER_GPU                 2\n","IMAGE_CHANNEL_COUNT            3\n","IMAGE_MAX_DIM                  1024\n","IMAGE_META_SIZE                14\n","IMAGE_MIN_DIM                  800\n","IMAGE_MIN_SCALE                0\n","IMAGE_RESIZE_MODE              square\n","IMAGE_SHAPE                    [1024 1024    3]\n","LEARNING_MOMENTUM              0.9\n","LEARNING_RATE                  0.001\n","LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n","MASK_POOL_SIZE                 14\n","MASK_SHAPE                     [28, 28]\n","MAX_GT_INSTANCES               100\n","MEAN_PIXEL                     [123.7 116.8 103.9]\n","MINI_MASK_SHAPE                (56, 56)\n","NAME                           amoeba_cfg\n","NUM_CLASSES                    2\n","POOL_SIZE                      7\n","POST_NMS_ROIS_INFERENCE        1000\n","POST_NMS_ROIS_TRAINING         2000\n","PRE_NMS_LIMIT                  6000\n","ROI_POSITIVE_RATIO             0.33\n","RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n","RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n","RPN_ANCHOR_STRIDE              1\n","RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n","RPN_NMS_THRESHOLD              0.7\n","RPN_TRAIN_ANCHORS_PER_IMAGE    256\n","STEPS_PER_EPOCH                131\n","TOP_DOWN_PYRAMID_SIZE          256\n","TRAIN_BN                       False\n","TRAIN_ROIS_PER_IMAGE           200\n","USE_MINI_MASK                  True\n","USE_RPN_ROIS                   True\n","VALIDATION_STEPS               50\n","WEIGHT_DECAY                   0.0001\n","\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"GTy9wXmK8w3E"},"source":["# Train custom amoeba model"]},{"cell_type":"markdown","source":["In machine learning, to improve something you often need to be able to measure it. TensorBoard is a tool for providing the measurements and visualizations needed during the machine learning workflow. More information about Tensorboard is available here (https://www.tensorflow.org/tensorboard/get_started)."],"metadata":{"id":"_u6LGuPrHSsD"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gB1kiNlUAMGM","outputId":"f7e89d58-a32a-45de-eb49-42b755ffa409","executionInfo":{"status":"ok","timestamp":1655762879843,"user_tz":240,"elapsed":777,"user":{"displayName":"Baosen Zhang","userId":"17675451703526793530"}}},"source":["# run tensorboard to visualize training\n","import keras\n","import os\n","root_logdir = os.path.join(os.curdir, \"my_logs\")\n","def get_run_logdir():\n","    import time\n","    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n","    return os.path.join(root_logdir, run_id)\n","\n","run_logdir = get_run_logdir()\n","print(run_logdir)\n","tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["./my_logs/run_2022_06_20-22_07_58\n"]}]},{"cell_type":"markdown","source":["The Mask R-CNN structure is described in the paper(He, K., Gkioxari, G., Dollár, P. and Girshick, R., 2017. Mask r-cnn. In Proceedings of the IEEE international conference on computer vision (pp. 2961-2969).) and also in my ppt."],"metadata":{"id":"bOBDZ9ADHVe5"}},{"cell_type":"markdown","source":["Train in two stages:\n","1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n","\n","2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."],"metadata":{"id":"Dt5p3vxDgwcf"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5aqMMXOh_XRG","outputId":"d5cb600d-d5f5-45cc-dc60-c484213dbaa4","executionInfo":{"status":"ok","timestamp":1655764739303,"user_tz":240,"elapsed":1859467,"user":{"displayName":"Baosen Zhang","userId":"17675451703526793530"}}},"source":["# train the model\n","model = MaskRCNN(mode='training', model_dir='./', config=config)\n","model.load_weights('Mask_RCNN/mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\n","model.train(train_set, val_set, learning_rate=0.002, epochs=10, layers='heads', custom_callbacks=[tensorboard_cb])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:508: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3837: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3661: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1944: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:553: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n","\n","WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:600: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:168: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:175: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:180: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:184: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:193: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:200: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","\n","Starting at epoch 0. LR=0.002\n","\n","Checkpoint Path: ./amoeba_cfg20220620T2208/mask_rcnn_amoeba_cfg_{epoch:04d}.h5\n","Selecting layers to train\n","fpn_c5p5               (Conv2D)\n","fpn_c4p4               (Conv2D)\n","fpn_c3p3               (Conv2D)\n","fpn_c2p2               (Conv2D)\n","fpn_p5                 (Conv2D)\n","fpn_p2                 (Conv2D)\n","fpn_p3                 (Conv2D)\n","fpn_p4                 (Conv2D)\n","In model:  rpn_model\n","    rpn_conv_shared        (Conv2D)\n","    rpn_class_raw          (Conv2D)\n","    rpn_bbox_pred          (Conv2D)\n","mrcnn_mask_conv1       (TimeDistributed)\n","mrcnn_mask_bn1         (TimeDistributed)\n","mrcnn_mask_conv2       (TimeDistributed)\n","mrcnn_mask_bn2         (TimeDistributed)\n","mrcnn_class_conv1      (TimeDistributed)\n","mrcnn_class_bn1        (TimeDistributed)\n","mrcnn_mask_conv3       (TimeDistributed)\n","mrcnn_mask_bn3         (TimeDistributed)\n","mrcnn_class_conv2      (TimeDistributed)\n","mrcnn_class_bn2        (TimeDistributed)\n","mrcnn_mask_conv4       (TimeDistributed)\n","mrcnn_mask_bn4         (TimeDistributed)\n","mrcnn_bbox_fc          (TimeDistributed)\n","mrcnn_mask_deconv      (TimeDistributed)\n","mrcnn_class_logits     (TimeDistributed)\n","mrcnn_mask             (TimeDistributed)\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:977: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:964: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2087: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n","  UserWarning('Using a generator with `use_multiprocessing=True`'\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:783: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:786: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n","Epoch 1/10\n","130/131 [============================>.] - ETA: 1s - loss: 0.8721 - rpn_class_loss: 0.0130 - rpn_bbox_loss: 0.1436 - mrcnn_class_loss: 0.0538 - mrcnn_bbox_loss: 0.3238 - mrcnn_mask_loss: 0.3379"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2348: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n","  UserWarning('Using a generator with `use_multiprocessing=True`'\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r131/131 [==============================] - 215s 2s/step - loss: 0.8721 - rpn_class_loss: 0.0130 - rpn_bbox_loss: 0.1441 - mrcnn_class_loss: 0.0535 - mrcnn_bbox_loss: 0.3228 - mrcnn_mask_loss: 0.3387 - val_loss: 0.7182 - val_rpn_class_loss: 0.0032 - val_rpn_bbox_loss: 0.1747 - val_mrcnn_class_loss: 0.0286 - val_mrcnn_bbox_loss: 0.2218 - val_mrcnn_mask_loss: 0.2899\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:869: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n","\n","Epoch 2/10\n","131/131 [==============================] - 171s 1s/step - loss: 0.5120 - rpn_class_loss: 0.0046 - rpn_bbox_loss: 0.1111 - mrcnn_class_loss: 0.0273 - mrcnn_bbox_loss: 0.1433 - mrcnn_mask_loss: 0.2258 - val_loss: 0.6222 - val_rpn_class_loss: 0.0033 - val_rpn_bbox_loss: 0.1797 - val_mrcnn_class_loss: 0.0219 - val_mrcnn_bbox_loss: 0.1731 - val_mrcnn_mask_loss: 0.2441\n","Epoch 3/10\n","131/131 [==============================] - 173s 1s/step - loss: 0.4560 - rpn_class_loss: 0.0045 - rpn_bbox_loss: 0.1109 - mrcnn_class_loss: 0.0255 - mrcnn_bbox_loss: 0.1106 - mrcnn_mask_loss: 0.2046 - val_loss: 0.6388 - val_rpn_class_loss: 0.0035 - val_rpn_bbox_loss: 0.1844 - val_mrcnn_class_loss: 0.0295 - val_mrcnn_bbox_loss: 0.1575 - val_mrcnn_mask_loss: 0.2638\n","Epoch 4/10\n","131/131 [==============================] - 174s 1s/step - loss: 0.3960 - rpn_class_loss: 0.0041 - rpn_bbox_loss: 0.1067 - mrcnn_class_loss: 0.0203 - mrcnn_bbox_loss: 0.0795 - mrcnn_mask_loss: 0.1855 - val_loss: 0.6844 - val_rpn_class_loss: 0.0026 - val_rpn_bbox_loss: 0.2651 - val_mrcnn_class_loss: 0.0168 - val_mrcnn_bbox_loss: 0.1498 - val_mrcnn_mask_loss: 0.2501\n","Epoch 5/10\n","131/131 [==============================] - 174s 1s/step - loss: 0.3678 - rpn_class_loss: 0.0036 - rpn_bbox_loss: 0.1026 - mrcnn_class_loss: 0.0191 - mrcnn_bbox_loss: 0.0644 - mrcnn_mask_loss: 0.1782 - val_loss: 0.6139 - val_rpn_class_loss: 0.0034 - val_rpn_bbox_loss: 0.1611 - val_mrcnn_class_loss: 0.0165 - val_mrcnn_bbox_loss: 0.1572 - val_mrcnn_mask_loss: 0.2758\n","Epoch 6/10\n","131/131 [==============================] - 174s 1s/step - loss: 0.2994 - rpn_class_loss: 0.0031 - rpn_bbox_loss: 0.0712 - mrcnn_class_loss: 0.0148 - mrcnn_bbox_loss: 0.0503 - mrcnn_mask_loss: 0.1601 - val_loss: 0.5550 - val_rpn_class_loss: 0.0035 - val_rpn_bbox_loss: 0.1496 - val_mrcnn_class_loss: 0.0191 - val_mrcnn_bbox_loss: 0.1417 - val_mrcnn_mask_loss: 0.2411\n","Epoch 7/10\n","131/131 [==============================] - 175s 1s/step - loss: 0.2713 - rpn_class_loss: 0.0024 - rpn_bbox_loss: 0.0660 - mrcnn_class_loss: 0.0132 - mrcnn_bbox_loss: 0.0393 - mrcnn_mask_loss: 0.1503 - val_loss: 0.6330 - val_rpn_class_loss: 0.0036 - val_rpn_bbox_loss: 0.2303 - val_mrcnn_class_loss: 0.0334 - val_mrcnn_bbox_loss: 0.1221 - val_mrcnn_mask_loss: 0.2436\n","Epoch 8/10\n","131/131 [==============================] - 175s 1s/step - loss: 0.2462 - rpn_class_loss: 0.0023 - rpn_bbox_loss: 0.0571 - mrcnn_class_loss: 0.0115 - mrcnn_bbox_loss: 0.0351 - mrcnn_mask_loss: 0.1401 - val_loss: 0.5879 - val_rpn_class_loss: 0.0022 - val_rpn_bbox_loss: 0.1540 - val_mrcnn_class_loss: 0.0195 - val_mrcnn_bbox_loss: 0.1375 - val_mrcnn_mask_loss: 0.2748\n","Epoch 9/10\n","131/131 [==============================] - 175s 1s/step - loss: 0.2270 - rpn_class_loss: 0.0018 - rpn_bbox_loss: 0.0529 - mrcnn_class_loss: 0.0106 - mrcnn_bbox_loss: 0.0294 - mrcnn_mask_loss: 0.1323 - val_loss: 0.5899 - val_rpn_class_loss: 0.0031 - val_rpn_bbox_loss: 0.1676 - val_mrcnn_class_loss: 0.0200 - val_mrcnn_bbox_loss: 0.1252 - val_mrcnn_mask_loss: 0.2740\n","Epoch 10/10\n","131/131 [==============================] - 177s 1s/step - loss: 0.2035 - rpn_class_loss: 0.0021 - rpn_bbox_loss: 0.0434 - mrcnn_class_loss: 0.0117 - mrcnn_bbox_loss: 0.0236 - mrcnn_mask_loss: 0.1227 - val_loss: 0.5572 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.1872 - val_mrcnn_class_loss: 0.0318 - val_mrcnn_bbox_loss: 0.1108 - val_mrcnn_mask_loss: 0.2248\n"]}]},{"cell_type":"markdown","metadata":{"id":"IXf0LbQz1IWk"},"source":["# Evaluate amoeba model\n"," \n"]},{"cell_type":"markdown","source":["Evaluate the mask rcnn model on the training, validation and test amoeba dataset"],"metadata":{"id":"iZ-g5om6B63p"}},{"cell_type":"code","source":["from os import listdir\n","from xml.etree import ElementTree\n","from numpy import zeros\n","from numpy import asarray\n","from numpy import expand_dims\n","from numpy import mean\n","from mrcnn.config import Config\n","from mrcnn.model import MaskRCNN\n","from mrcnn.utils import Dataset\n","from mrcnn.utils import compute_ap\n","from mrcnn.model import load_image_gt\n","from mrcnn.model import mold_image\n","\n","class PredictionConfig(Config):\n","\tNAME = \"amoeba_cfg\"\n","\tNUM_CLASSES = 1 + 1\n","\tGPU_COUNT = 1\n","\tIMAGES_PER_GPU = 1\n","\n","# calculate the mAP for a model on a given dataset\n","def evaluate_model(dataset, model, cfg):\n","\tAPs = list()\n","\tfor image_id in dataset.image_ids:\n","\t\timage, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n","\t\tscaled_image = mold_image(image, cfg)\n","\t\tsample = expand_dims(scaled_image, 0)\n","\t\tyhat = model.detect(sample, verbose=0)\n","\t\tr = yhat[0]\n","\t\tAP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n","\t\tAPs.append(AP)\n","\tmAP = mean(APs)\n","\treturn mAP\n"],"metadata":{"id":"LvMEnCcC4nmj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create config\n","cfg = PredictionConfig()\n","# define the model\n","model = MaskRCNN(mode='inference', model_dir='./', config=cfg)\n","\n","# !!!load model weights\n","# Get path to saved weights\n","# Either set a specific path or find last trained weights\n","# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n","# find last trained weights: \n","model_path = model.find_last()\n","model.load_weights(model_path, by_name=True)\n","\n","# set a specific path\n","#model.load_weights('amoeba_cfg20210206T1746/mask_rcnn_amoeba_cfg_0007.h5', by_name=True)  # change the weights path to run the code"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ek-C09UD5OLZ","executionInfo":{"status":"ok","timestamp":1655764748310,"user_tz":240,"elapsed":9016,"user":{"displayName":"Baosen Zhang","userId":"17675451703526793530"}},"outputId":"1c6f032a-9382-4fe0-cae7-d1f0e31afcea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n","\n","WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n","\n","WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","Re-starting from epoch 10\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YjH_BfMA1CDX","outputId":"ec182026-a133-4c70-91f9-3afbf6c49ef2","executionInfo":{"status":"ok","timestamp":1655764846184,"user_tz":240,"elapsed":97886,"user":{"displayName":"Baosen Zhang","userId":"17675451703526793530"}}},"source":["# load the train dataset\n","train_set = AmoebaDataset()\n","train_set.load_dataset('trainingDataset', is_train=True)\n","train_set.prepare()\n","print('Train: %d' % len(train_set.image_ids))\n","# load the val dataset\n","val_set = AmoebaDataset()\n","val_set.load_dataset('trainingDataset', is_train=False)\n","val_set.prepare()\n","print('Val: %d' % len(val_set.image_ids))\n","# load the test dataset\n","test_set = AmoebaDataset()\n","test_set.load_dataset('testDataset')\n","test_set.prepare()\n","print('Test: %d' % len(test_set.image_ids))\n","\n","\n","# evaluate model on training dataset\n","train_mAP = evaluate_model(train_set, model, cfg)\n","print(\"Train mAP: %.3f\" % train_mAP)\n","# evaluate model on test dataset\n","val_mAP = evaluate_model(val_set, model, cfg)\n","print(\"Val mAP: %.3f\" % val_mAP)\n","# evaluate model on test dataset\n","test_mAP = evaluate_model(test_set, model, cfg)\n","print(\"Test mAP: %.3f\" % test_mAP)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train: 169\n","Val: 27\n","Test: 20\n","Train mAP: 0.918\n","Val mAP: 0.880\n","Test mAP: 0.883\n"]}]},{"cell_type":"code","source":["# visualize training in Tensorboard\n","\n","# The tensorboard file name can be found in 'my_logs'. Then change the tensorboard file name.\n","\n","# %load_ext tensorboard\n","# %tensorboard --logdir ./my_logs/run_2022_06_20-22_07_58"],"metadata":{"id":"DNP2wqXpHmTG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ESecZKkV2_M1"},"source":["# Inference\n"]},{"cell_type":"markdown","metadata":{"id":"NQjYvkVaosFu"},"source":["## Drop inference"]},{"cell_type":"markdown","source":["The concentration of amoebae in a sample can be determined by imaging an entire drop of a particular volume of the sample and counting the number of amoebae present there. The models described above were used to analyze the images of the entire drop and count the number of bounding boxes within all images. \n","\n","There are 6 drops examples. Students can change the file location to do inference on each of the drop. "],"metadata":{"id":"2nlMT57FZBF8"}},{"cell_type":"markdown","source":["We will detect the images in testDataset folder by calling model.detect()."],"metadata":{"id":"TLn-lYsaISBR"}},{"cell_type":"code","source":["from matplotlib import pyplot\n","from matplotlib.patches import Rectangle\n","\n","  \n","def count1_amoeba(image, model, cfg):\n","  image = np.asanyarray(image)\n","  scaled_image = mold_image(image, cfg)\n","  sample = expand_dims(image, 0)\n","  yhat = model.detect(sample, verbose=0)[0]\n","  \n","  count=0\n","  for box,confidence in zip(yhat['rois'],yhat['scores']):\n","    if confidence >=0.96:\n","      count = count +1\n","  print(\"The number of amoeba is \", count)\n","  return count\n","\n","def save_predicted(image, model, cfg, filename):\n","  image = np.asanyarray(image)\n","  scaled_image = mold_image(image, cfg)\n","  sample = expand_dims(image, 0)\n","  yhat = model.detect(sample, verbose=0)[0]\n","  pyplot.imshow(image)\n","  ax = pyplot.gca()\n","  pyplot.axis(\"off\")\n","  for box,confidence in zip(yhat['rois'],yhat['scores']):\n","    if confidence >= 0.96:\n","      y1, x1, y2, x2 = box\n","      width, height = x2 - x1, y2 - y1\n","      rect = Rectangle((x1, y1), width, height, fill=False, color='red')\n","      pyplot.text(x1,y1,confidence)\n","      ax.add_patch(rect)\n","\n","  pyplot.savefig(filename,bbox_inches='tight',pad_inches=0.0)\n","  pyplot.show()\n"],"metadata":{"id":"8mbAJUPZSCyl"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5iRklVsBn9qE","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1guSn4BOYCgpTNnbsAG27dp2YJP_Zc-dR"},"executionInfo":{"status":"ok","timestamp":1655764881995,"user_tz":240,"elapsed":35845,"user":{"displayName":"Baosen Zhang","userId":"17675451703526793530"}},"outputId":"8bc446fc-d8ee-43b3-fc3b-5ff73a4a28cc"},"source":["# create folder to save inference images\n","from PIL import Image\n","if not os.path.exists(\"drop1-inference\"):\n","  os.mkdir(\"drop1-inference\")\n","\n","# find the path of original inference images\n","images_dir = \"amoeba-detection/dataset-level2/dropInference/drop1/drop1\"\n","save_root = \"drop1-inference/\"\n","# run the inference and count the amoeba\n","t=0\n","for img in listdir(images_dir):\n","  img_path = images_dir + \"/\" + img\n","  image = Image.open(img_path)\n","  image = np.asanyarray(image)\n","  save_file = save_root + img\n","  save_predicted(image, model, cfg, save_file)\n","  t=t + count1_amoeba(image,model,cfg)\n","  print(t)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"B3YyoNMioZDZ"},"source":["# save the inference folder to local\n","\n","# !zip -r drop1-inference.zip drop1-inference\n","# from google.colab import files\n","# files.download(\"drop1-inference.zip\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4_uw7QD115NJ"},"source":["## Test dataset inference"]},{"cell_type":"code","metadata":{"id":"sD45PtNO13_5","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1-GIZwn_KXXWsp98TUJbG1EbWicJzxV_7"},"executionInfo":{"status":"ok","timestamp":1655764902139,"user_tz":240,"elapsed":20161,"user":{"displayName":"Baosen Zhang","userId":"17675451703526793530"}},"outputId":"9e3e116f-cc15-4c5a-f64b-899d736972f0"},"source":["# create folder to save inference images\n","from PIL import Image\n","if not os.path.exists(\"testDataset-pred\"):\n","  os.mkdir(\"testDataset-pred\")\n","\n","# find the path of original inference images\n","images_dir = \"amoeba-detection/dataset-level2/amoebaDataset/testDataset/images\"\n","save_root = \"testDataset-pred/\"\n","# run the inference and count the amoeba\n","t=0\n","for img in listdir(images_dir):\n","  img_path = images_dir + \"/\" + img\n","  image = Image.open(img_path)\n","  image = np.asanyarray(image)\n","  save_file = save_root + img\n","  save_predicted(image, model, cfg, save_file)\n","  t=t + count1_amoeba(image,model,cfg)\n","  print(t)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"lk_EIqRV2VLL"},"source":["# save the inference folder to local\n","\n","# !zip -r testDataset-pred.zip testDataset-pred\n","# from google.colab import files\n","# files.download(\"testDataset-pred.zip\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cgSmFfk0--o0"},"source":["## Prediction time"]},{"cell_type":"code","source":["# estimate the prediction time\n","\n","from PIL import Image\n","import time\n","if not os.path.exists(\"testDataset-pred\"):\n","  os.mkdir(\"testDataset-pred\")\n","\n","# find the path of original inference images\n","images_dir = \"amoeba-detection/dataset-level2/amoebaDataset/testDataset/images\"\n","save_root = \"testDataset-pred/\"\n","# run the inference and count the amoeba\n","\n","for img in listdir(images_dir):\n","  start = time.time()\n","  img_path = images_dir + \"/\" + img\n","  image = Image.open(img_path)\n","  image = np.asanyarray(image)\n","  save_file = save_root + img\n","  save_predicted(image, model, cfg, save_file)\n","  end = time.time()\n","  predTime = end - start\n","  print(\"prediction time is \" + str(predTime) + \"s\")"],"metadata":{"id":"mYOWgqAi6lFh","colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1RV6zCmjFH0A9maA99USgdeG2vpeqslkd"},"executionInfo":{"status":"ok","timestamp":1655764915361,"user_tz":240,"elapsed":13229,"user":{"displayName":"Baosen Zhang","userId":"17675451703526793530"}},"outputId":"5a4bc3f9-6b2c-46d4-8f5f-44598d938728"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}